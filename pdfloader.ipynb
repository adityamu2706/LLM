{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'youtube_transcript_api'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 13\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mhtmlTemplates\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m css, bot_template, user_template\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_openai\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m OpenAI\n\u001b[0;32m---> 13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01myoutube_transcript_api\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m YouTubeTranscriptApi\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'youtube_transcript_api'"
     ]
    }
   ],
   "source": [
    "import streamlit as st\n",
    "import time\n",
    "import os\n",
    "from PyPDF2 import PdfReader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from htmlTemplates import css, bot_template, user_template\n",
    "from langchain_openai import OpenAI\n",
    "from youtube_transcript_api import YouTubeTranscriptApi\n",
    "\n",
    "youtube_ids = []\n",
    "    \n",
    "    id = st.sidebar.text_input(f\"URL {1}\")\n",
    "    youtube_ids.append(id)\n",
    "    transcript_list = YouTubeTranscriptApi.list_transcripts(youtube_ids[0])\n",
    "    transcript = transcript_list.find_generated_transcript(['de', 'en'])\n",
    "\n",
    "    text_splitter = CharacterTextSplitter(\n",
    "        separator=\"\\n\",\n",
    "        chunk_size=1000,\n",
    "        chunk_overlap=200,\n",
    "        length_function=len\n",
    "    )\n",
    "\n",
    "    chunks = text_splitter.split_text(transcript)\n",
    "\n",
    "    embeddings = OpenAIEmbeddings()\n",
    "    vectorstore = FAISS.from_texts(texts=chunks, embedding=embeddings)\n",
    "\n",
    "    llm = ChatOpenAI()\n",
    "    memory = ConversationBufferMemory(\n",
    "        memory_key='chat_history', return_messages=True)\n",
    "    \n",
    "    conversation_chain = ConversationalRetrievalChain.from_llm(\n",
    "        llm=llm,\n",
    "        retriever=vectorstore.as_retriever(),\n",
    "        memory=memory\n",
    "    )\n",
    "\n",
    "    user_question = st.text_input(\"Ask a question about your videos:\")\n",
    "    response = st.session_state.conversation({'question': user_question})\n",
    "    st.session_state.chat_history = response['chat_history'] \n",
    "\n",
    "    if user_question:\n",
    "        if st.button(\"Process\"): \n",
    "            for i, message in enumerate(st.session_state.chat_history):\n",
    "                if i % 2 == 0:\n",
    "                    st.write(user_template.replace(\n",
    "                        \"{{MSG}}\", message.content), unsafe_allow_html=True)\n",
    "                else:\n",
    "                    st.write(bot_template.replace(\n",
    "                        \"{{MSG}}\", message.content), unsafe_allow_html=True)\n",
    "    \n",
    "    st.markdown(\"\"\"\n",
    "    <style>\n",
    "        [data-testid=stSidebar] {\n",
    "            background-color: #008080;\n",
    "        }\n",
    "    </style>\n",
    "    \"\"\", unsafe_allow_html=True)\n",
    "\n",
    "    with st.sidebar:\n",
    "        st.subheader(\"Your videos\")\n",
    "        pdf_docs = st.file_uploader(\n",
    "            \"Insert the video-ids here'\", accept_multiple_files=True)\n",
    "    \n",
    "    # create conversation chain\n",
    "    st.session_state.conversation = get_conversation_chain(\n",
    "       vectorstore)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'YouTubeTranscriptApi' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mid\u001b[39m \u001b[38;5;241m=\u001b[39m st\u001b[38;5;241m.\u001b[39msidebar\u001b[38;5;241m.\u001b[39mtext_input(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mURL \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      4\u001b[0m youtube_ids\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mid\u001b[39m)\n\u001b[0;32m----> 5\u001b[0m transcript_list \u001b[38;5;241m=\u001b[39m \u001b[43mYouTubeTranscriptApi\u001b[49m\u001b[38;5;241m.\u001b[39mlist_transcripts(youtube_ids[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m      6\u001b[0m transcript \u001b[38;5;241m=\u001b[39m transcript_list\u001b[38;5;241m.\u001b[39mfind_generated_transcript([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mde\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124men\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m      8\u001b[0m text_splitter \u001b[38;5;241m=\u001b[39m CharacterTextSplitter(\n\u001b[1;32m      9\u001b[0m     separator\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     10\u001b[0m     chunk_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000\u001b[39m,\n\u001b[1;32m     11\u001b[0m     chunk_overlap\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m200\u001b[39m,\n\u001b[1;32m     12\u001b[0m     length_function\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m\n\u001b[1;32m     13\u001b[0m )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'YouTubeTranscriptApi' is not defined"
     ]
    }
   ],
   "source": [
    "youtube_ids = []\n",
    "\n",
    "id = st.sidebar.text_input(f\"URL {1}\")\n",
    "youtube_ids.append(id)\n",
    "transcript_list = YouTubeTranscriptApi.list_transcripts(youtube_ids[0])\n",
    "transcript = transcript_list.find_generated_transcript(['de', 'en'])\n",
    "\n",
    "text_splitter = CharacterTextSplitter(\n",
    "    separator=\"\\n\",\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=200,\n",
    "    length_function=len\n",
    ")\n",
    "chunks = text_splitter.split_text(transcript)\n",
    "\n",
    "embeddings = OpenAIEmbeddings()\n",
    "vectorstore = FAISS.from_texts(texts=chunks, embedding=embeddings)\n",
    "\n",
    "llm = ChatOpenAI()\n",
    "memory = ConversationBufferMemory(\n",
    "    memory_key='chat_history', return_messages=True)\n",
    "conversation_chain = ConversationalRetrievalChain.from_llm(\n",
    "    llm=llm,\n",
    "    retriever=vectorstore.as_retriever(),\n",
    "    memory=memory\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-19 03:39:51.639 \n",
      "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
      "  command:\n",
      "\n",
      "    streamlit run /opt/homebrew/lib/python3.11/site-packages/ipykernel_launcher.py [ARGUMENTS]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "cannot pickle '_thread.RLock' object",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m file_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvector_index.pkl\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(file_path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m---> 10\u001b[0m     \u001b[43mpickle\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvectorindex_openai\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(file_path):\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(file_path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n",
      "\u001b[0;31mTypeError\u001b[0m: cannot pickle '_thread.RLock' object"
     ]
    }
   ],
   "source": [
    "#Creating vector embeddings\n",
    "embeddings = OpenAIEmbeddings()\n",
    "#FaiSS - the vector database - takes the docs(chunks) and vector embeddings\n",
    "#as input\n",
    "vectorindex_openai = FAISS.from_documents(docs, embeddings)\n",
    "\n",
    "\n",
    "file_path = \"vector_index.pkl\"\n",
    "with open(file_path, \"wb\") as f:\n",
    "    pickle.dump(vectorindex_openai, f)\n",
    "\n",
    "if os.path.exists(file_path):\n",
    "    with open(file_path, \"rb\") as f:\n",
    "        vectorIndex = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = RetrievalQAWithSourcesChain.from_llm(llm=llm, retriever=vectorIndex.as_retriever())\n",
    "query = \"What is the best restaurant in Ann Arbor?\"\n",
    "\n",
    "langchain.debug=True\n",
    "\n",
    "chain({\"question\": query}, return_only_outputs=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
